cd src && make test
make[1]: Entering directory '/benchmark-scripts/redis-src/src'
Cleanup: may take some time... OK
Starting test server at port 11111
[ready]: 232
Testing unit/printver
[ready]: 230
Testing unit/dump
[ready]: 231
Testing unit/auth
[ready]: 234
Testing unit/protocol
[ready]: 233
Testing unit/keyspace
[ready]: 235
Testing unit/scan
[ready]: 236
Testing unit/type/string
[ready]: 237
Testing unit/type/incr
[ready]: 238
Testing unit/type/list
[ready]: 240
Testing unit/type/list-2
[ready]: 239
Testing unit/type/list-3
[ready]: 241
Testing unit/type/set
[ready]: 243
Testing unit/type/zset
[ready]: 245
Testing unit/type/hash
[ready]: 244
Testing unit/sort
[ready]: 242
Testing unit/expire
[ok]: INCR against non existing key
[ok]: INCR against key created by incr itself
[ok]: INCR against key originally set with SET
[ok]: INCR over 32bit value
[ok]: INCRBY over 32bit value with over 32bit increment
[ok]: INCR fails against key with spaces (left)
[ok]: INCR fails against key with spaces (right)
[ok]: INCR fails against key with spaces (both)
[ok]: INCR fails against a key holding a list
[ok]: DECRBY over 32bit value with over 32bit increment, negative res
[ok]: INCR uses shared objects in the 0-9999 range
[ok]: Explicit regression for a list bug
[ok]: INCR can modify objects in-place
[ok]: INCRBYFLOAT against non existing key
[ok]: INCRBYFLOAT against key originally set with SET
[ok]: INCRBYFLOAT over 32bit value
[ok]: EXPIRE - set timeouts multiple times
[ok]: INCRBYFLOAT over 32bit value with over 32bit increment
[ok]: EXPIRE - It should be still possible to read 'x'
[ok]: INCRBYFLOAT fails against key with spaces (left)
[ok]: INCRBYFLOAT fails against key with spaces (right)
[ok]: INCRBYFLOAT fails against key with spaces (both)
[ok]: INCRBYFLOAT fails against a key holding a list
[ok]: INCRBYFLOAT does not allow NaN or Infinity
[ok]: INCRBYFLOAT decrement
[ok]: string to double with null terminator
[ok]: HSET/HLEN - Small hash creation
[ok]: Is the small hash encoded with a ziplist?
[ok]: DEL against a single item
[ok]: Vararg DEL
[ok]: KEYS with pattern
[ok]: KEYS to get all keys
[ok]: DBSIZE
[ok]: DEL all keys
[ok]: AUTH fails if there is no password configured server side
[ok]: Old Ziplist: SORT BY key
[ok]: Old Ziplist: SORT BY key with limit
[ok]: Old Ziplist: SORT BY hash field
[ok]: DUMP / RESTORE are able to serialize / unserialize a simple key
[ok]: RESTORE can set an arbitrary expire to the materialized key
[ok]: SADD, SCARD, SISMEMBER, SMEMBERS basics - regular set
[ok]: RESTORE can set an expire that overflows a 32 bit integer
[ok]: RESTORE returns an error of the key already exists
[ok]: SADD, SCARD, SISMEMBER, SMEMBERS basics - intset
[ok]: SADD against non set
[ok]: RESTORE can overwrite an existing key with REPLACE
[ok]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - ziplist
[ok]: RESTORE can detect a syntax error for unrecongized options
[ok]: DUMP of non existing key returns nil
[ok]: SADD a non-integer against an intset
[ok]: SADD an integer larger than 64 bits
[ok]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - regular list
[ok]: R/LPOP against empty list
[ok]: Variadic RPUSH/LPUSH
[ok]: DEL a list
[ok]: BLPOP, BRPOP: single existing list - linkedlist
[ok]: BLPOP, BRPOP: multiple existing lists - linkedlist
[ok]: BLPOP, BRPOP: second list has an entry - linkedlist
[ok]: BRPOPLPUSH - linkedlist
[ok]: BLPOP, BRPOP: single existing list - ziplist
[ok]: BLPOP, BRPOP: multiple existing lists - ziplist
[ok]: BLPOP, BRPOP: second list has an entry - ziplist
[ok]: BRPOPLPUSH - ziplist
[ok]: BLPOP, LPUSH + DEL should not awake blocked client
[ok]: BLPOP, LPUSH + DEL + SET should not awake blocked client
[ok]: BLPOP with same key multiple times should work (issue #801)
[ok]: MULTI/EXEC is isolated from the point of view of BLPOP
[ok]: BLPOP with variadic LPUSH
[ok]: SCAN basic
Testing Redis version 4.0.14 (00000000)
[ok]: SET and GET an item
[ok]: SET and GET an empty item
[ok]: Handle an empty query
[ok]: Check encoding - ziplist
[ok]: ZSET basic ZADD and score update - ziplist
[ok]: ZSET element can't be set to NaN with ZADD - ziplist
[ok]: ZSET element can't be set to NaN with ZINCRBY
[ok]: ZADD with options syntax error with incomplete pair
[ok]: ZADD XX option without key - ziplist
[ok]: ZADD XX existing key - ziplist
[ok]: ZADD XX returns the number of elements actually added
[ok]: ZADD XX updates existing elements score
[ok]: ZADD XX and NX are not compatible
[ok]: ZADD NX with non exisitng key
[ok]: Regression for quicklist #3343 bug
[ok]: ZADD NX only add new elements without updating old ones
[ok]: ZADD INCR works like ZINCRBY
[ok]: ZADD INCR works with a single score-elemenet pair
[ok]: ZADD CH option changes return value to all changed elements
[ok]: ZINCRBY calls leading to NaN result in error
[ok]: ZADD - Variadic version base case
[ok]: ZADD - Return value is the number of actually added items
[ok]: ZADD - Variadic version does not add nothing on single parsing err
[ok]: ZADD - Variadic version will raise error on missing arg
[ok]: ZINCRBY does not work variadic even if shares ZADD implementation
[ok]: ZCARD basics - ziplist
[ok]: ZREM removes key after last element is removed
[ok]: ZREM variadic version
[ok]: ZREM variadic version -- remove elements after key deletion
[ok]: ZRANGE basics - ziplist
[ok]: ZREVRANGE basics - ziplist
[ok]: ZRANK/ZREVRANK basics - ziplist
[ok]: ZRANK - after deletion - ziplist
[ok]: ZINCRBY - can create a new sorted set - ziplist
[ok]: HSET/HLEN - Big hash creation
[ok]: Is the big hash encoded with an hash table?
[ok]: HGET against the small hash
[ok]: ZINCRBY - increment and decrement - ziplist
[ok]: ZINCRBY return value
[ok]: SADD overflows the maximum allowed integers in an intset
[ok]: Variadic SADD
[ok]: Negative multibulk length
[ok]: Out of range multibulk length
[ok]: Wrong multibulk payload header
[ok]: Negative multibulk payload length
[ok]: Out of range multibulk payload length
[ok]: Non-number multibulk payload length
[ok]: Multi bulk request not followed by bulk arguments
[ok]: Generic wrong number of args
[ok]: Unbalanced number of quotes
[ok]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics
[ok]: ZRANGEBYSCORE with WITHSCORES
[ok]: SCAN COUNT
[ok]: ZRANGEBYSCORE with LIMIT
[ok]: ZRANGEBYSCORE with LIMIT and WITHSCORES
[ok]: ZRANGEBYSCORE with non-value min or max
[ok]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics
[ok]: ZLEXCOUNT advanced
[ok]: ZRANGEBYSLEX with LIMIT
[ok]: ZRANGEBYLEX with invalid lex range specifiers
[ok]: ZREMRANGEBYSCORE basics
[ok]: ZREMRANGEBYSCORE with non-value min or max
[ok]: Very big payload in GET/SET
[ok]: SCAN MATCH
[ok]: HGET against the big hash
[ok]: HGET against non existing key
[ok]: HSET in update and insert mode
[ok]: HSETNX target key missing - small hash
[ok]: HSETNX target key exists - small hash
[ok]: HSETNX target key missing - big hash
[ok]: HSETNX target key exists - big hash
[ok]: HMSET wrong number of args
[ok]: HMSET - small hash
[ok]: SSCAN with encoding intset
[ok]: ZREMRANGEBYRANK basics
[ok]: ZUNIONSTORE against non-existing key doesn't set destination - ziplist
[1/46 done]: unit/type/incr (0 seconds)
Testing unit/other
[ok]: ZUNIONSTORE with empty set - ziplist
[ok]: ZUNIONSTORE basics - ziplist
[ok]: ZUNIONSTORE with weights - ziplist
[ok]: ZUNIONSTORE with a regular set and weights - ziplist
[ok]: ZUNIONSTORE with AGGREGATE MIN - ziplist
[ok]: ZUNIONSTORE with AGGREGATE MAX - ziplist
[ok]: ZINTERSTORE basics - ziplist
[ok]: ZINTERSTORE with weights - ziplist
[ok]: ZINTERSTORE with a regular set and weights - ziplist
[ok]: ZINTERSTORE with AGGREGATE MIN - ziplist
[ok]: ZINTERSTORE with AGGREGATE MAX - ziplist
[ok]: ZUNIONSTORE with +inf/-inf scores - ziplist
[ok]: ZUNIONSTORE with NaN weights ziplist
[ok]: ZINTERSTORE with +inf/-inf scores - ziplist
[ok]: ZINTERSTORE with NaN weights ziplist
[ok]: Check encoding - skiplist
[ok]: ZSET basic ZADD and score update - skiplist
[ok]: ZSET element can't be set to NaN with ZADD - skiplist
[ok]: ZSET element can't be set to NaN with ZINCRBY
[ok]: ZADD with options syntax error with incomplete pair
[ok]: ZADD XX option without key - skiplist
[ok]: ZADD XX existing key - skiplist
[ok]: ZADD XX returns the number of elements actually added
[ok]: ZADD XX updates existing elements score
[ok]: ZADD XX and NX are not compatible
[ok]: ZADD NX with non exisitng key
[ok]: ZADD NX only add new elements without updating old ones
[ok]: SSCAN with encoding hashtable
[ok]: ZADD INCR works like ZINCRBY
[ok]: ZADD INCR works with a single score-elemenet pair
[ok]: ZADD CH option changes return value to all changed elements
[ok]: ZINCRBY calls leading to NaN result in error
[ok]: ZADD - Variadic version base case
[ok]: ZADD - Return value is the number of actually added items
[ok]: ZADD - Variadic version does not add nothing on single parsing err
[ok]: HSCAN with encoding ziplist
[ok]: ZADD - Variadic version will raise error on missing arg
[ok]: ZINCRBY does not work variadic even if shares ZADD implementation
[ok]: ZCARD basics - skiplist
[ok]: ZREM removes key after last element is removed
[ok]: ZREM variadic version
[ok]: ZREM variadic version -- remove elements after key deletion
[ok]: ZRANGE basics - skiplist
[ok]: ZREVRANGE basics - skiplist
[ok]: ZRANK/ZREVRANK basics - skiplist
[ok]: ZRANK - after deletion - skiplist
[ok]: ZINCRBY - can create a new sorted set - skiplist
[ok]: ZINCRBY - increment and decrement - skiplist
[ok]: ZINCRBY return value
[ok]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics
[ok]: ZRANGEBYSCORE with WITHSCORES
[ok]: ZRANGEBYSCORE with LIMIT
[ok]: ZRANGEBYSCORE with LIMIT and WITHSCORES
[ok]: ZRANGEBYSCORE with non-value min or max
[ok]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics
[ok]: ZLEXCOUNT advanced
[ok]: ZRANGEBYSLEX with LIMIT
[ok]: ZRANGEBYLEX with invalid lex range specifiers
[ok]: ZREMRANGEBYSCORE basics
[ok]: ZREMRANGEBYSCORE with non-value min or max
[ok]: ZREMRANGEBYRANK basics
[ok]: ZUNIONSTORE against non-existing key doesn't set destination - skiplist
[ok]: ZUNIONSTORE with empty set - skiplist
[ok]: ZUNIONSTORE basics - skiplist
[ok]: ZUNIONSTORE with weights - skiplist
[ok]: ZUNIONSTORE with a regular set and weights - skiplist
[ok]: ZUNIONSTORE with AGGREGATE MIN - skiplist
[ok]: ZUNIONSTORE with AGGREGATE MAX - skiplist
[ok]: ZINTERSTORE basics - skiplist
[ok]: ZINTERSTORE with weights - skiplist
[ok]: ZINTERSTORE with a regular set and weights - skiplist
[ok]: ZINTERSTORE with AGGREGATE MIN - skiplist
[ok]: ZINTERSTORE with AGGREGATE MAX - skiplist
[ok]: ZUNIONSTORE with +inf/-inf scores - skiplist
[ok]: ZUNIONSTORE with NaN weights skiplist
[ok]: ZINTERSTORE with +inf/-inf scores - skiplist
[ok]: ZINTERSTORE with NaN weights skiplist
[ok]: ZINTERSTORE regression with two sets, intset+hashtable
[ok]: ZUNIONSTORE regression, should not create NaN in scores
[ok]: ZINTERSTORE #516 regression, mixed sets and ziplist zsets
[ok]: HMSET - big hash
[ok]: HMGET against non existing key and fields
[ok]: HMGET against wrong type
[ok]: HMGET - small hash
[2/46 done]: unit/printver (0 seconds)
Testing unit/multi
[ok]: HSCAN with encoding hashtable
[ok]: ZSCAN with encoding ziplist
[ok]: HMGET - big hash
[ok]: HKEYS - small hash
[ok]: Protocol desync regression test #1
[ok]: HKEYS - big hash
[ok]: HVALS - small hash
[ok]: HVALS - big hash
[ok]: HGETALL - small hash
[ok]: MIGRATE is caching connections
[ok]: ZSCAN with encoding skiplist
[ok]: ZUNIONSTORE result is sorted
[ok]: Protocol desync regression test #2
[ok]: ZSET commands don't accept the empty strings as valid score
[ok]: Old Linked list: SORT BY key
[ok]: Old Linked list: SORT BY key with limit
[ok]: Set encoding after DEBUG RELOAD
[ok]: ZSCORE - ziplist
[ok]: SREM basics - regular set
[ok]: SREM basics - intset
[ok]: SREM with multiple arguments
[ok]: SREM variadic version with more args needed to destroy the key
[ok]: Old Linked list: SORT BY hash field
[ok]: SCAN guarantees check under write load
[ok]: SSCAN with integer encoded object (issue #1345)
[ok]: SSCAN with PATTERN
[ok]: HSCAN with PATTERN
[ok]: ZSCAN with PATTERN
[ok]: SAVE - make sure there are all the types as values
[ok]: HGETALL - big hash
[ok]: HDEL and return value
[ok]: HDEL - more than a single value
[ok]: HDEL - hash becomes empty before deleting all specified fields
[ok]: HEXISTS
[ok]: Is a ziplist encoded Hash promoted on big payload?
[ok]: HINCRBY against non existing database key
[ok]: HINCRBY against non existing hash key
[ok]: HINCRBY against hash key created by hincrby itself
[ok]: HINCRBY against hash key originally set with HSET
[ok]: HINCRBY over 32bit value
[ok]: HINCRBY over 32bit value with over 32bit increment
[ok]: HINCRBY fails against hash value with spaces (left)
[ok]: HINCRBY fails against hash value with spaces (right)
[ok]: HINCRBY can detect overflows
[ok]: HINCRBYFLOAT against non existing database key
[ok]: ZSCORE after a DEBUG RELOAD - ziplist
[ok]: HINCRBYFLOAT against non existing hash key
[ok]: HINCRBYFLOAT against hash key created by hincrby itself
[ok]: HINCRBYFLOAT against hash key originally set with HSET
[ok]: HINCRBYFLOAT over 32bit value
[ok]: HINCRBYFLOAT over 32bit value with over 32bit increment
[ok]: HINCRBYFLOAT fails against hash value with spaces (left)
[ok]: HINCRBYFLOAT fails against hash value with spaces (right)
[ok]: HSTRLEN against the small hash
[ok]: Generated sets must be encoded as hashtable
[ok]: SINTER with two sets - hashtable
[ok]: SINTERSTORE with two sets - hashtable
[ok]: AUTH fails when a wrong password is given
[ok]: Arbitrary command gives an error when AUTH is required
[ok]: AUTH succeeds when the right password is given
[ok]: Once AUTH succeeded we can actually send commands to the server
[ok]: ZSCAN scores: regression test for issue #2175
[ok]: SINTERSTORE with two sets, after a DEBUG RELOAD - hashtable
[ok]: SUNION with two sets - hashtable
[ok]: ZSET sorting stresser - ziplist
[ok]: SUNIONSTORE with two sets - hashtable
[ok]: SINTER against three sets - hashtable
[ok]: SINTERSTORE with three sets - hashtable
[ok]: MUTLI / EXEC basics
[ok]: DISCARD
[ok]: Nested MULTI are not allowed
[ok]: MULTI where commands alter argc/argv
[ok]: WATCH inside MULTI is not allowed
[ok]: EXEC fails if there are errors while queueing commands #1
[ok]: EXEC fails if there are errors while queueing commands #2
[ok]: If EXEC aborts, the client MULTI state is cleared
[ok]: EXEC works on WATCHed key not modified
[ok]: EXEC fail on WATCHed key modified (1 key of 1 watched)
[ok]: EXEC fail on WATCHed key modified (1 key of 5 watched)
[ok]: EXEC fail on WATCHed key modified by SORT with STORE even if the result is empty
[ok]: After successful EXEC key is no longer watched
[ok]: After failed EXEC key is no longer watched
[ok]: It is possible to UNWATCH
[ok]: UNWATCH when there is nothing watched works as expected
[ok]: SUNION with non existing keys - hashtable
[ok]: SDIFF with two sets - hashtable
[ok]: SDIFF with three sets - hashtable
[ok]: SDIFFSTORE with three sets - hashtable
[ok]: FLUSHALL is able to touch the watched keys
[ok]: Protocol desync regression test #3
[ok]: HSTRLEN against the big hash
[ok]: HSTRLEN against non existing field
[ok]: HSTRLEN corner cases
[ok]: Hash ziplist regression test for large keys
[ok]: FLUSHALL does not touch non affected keys
[ok]: FLUSHDB is able to touch the watched keys
[ok]: FLUSHDB does not touch non affected keys
[ok]: WATCH is able to remember the DB a key belongs to
[ok]: WATCH will consider touched keys target of EXPIRE
[ok]: Hash fuzzing #1 - 10 fields
[ok]: Generated sets must be encoded as intset
[ok]: SINTER with two sets - intset
[ok]: SINTERSTORE with two sets - intset
[3/46 done]: unit/auth (1 seconds)
Testing unit/quit
[ok]: Hash fuzzing #2 - 10 fields
[ok]: SINTERSTORE with two sets, after a DEBUG RELOAD - intset
[ok]: SUNION with two sets - intset
[4/46 done]: unit/scan (1 seconds)
Testing unit/aofrw
[ok]: SUNIONSTORE with two sets - intset
[ok]: SINTER against three sets - intset
[ok]: SINTERSTORE with three sets - intset
[ok]: SUNION with non existing keys - intset
[ok]: SDIFF with two sets - intset
[ok]: SDIFF with three sets - intset
[ok]: SDIFFSTORE with three sets - intset
[ok]: SDIFF with first set empty
[ok]: SDIFF with same set two times
[ok]: QUIT returns OK
[ok]: Pipelined commands after QUIT must not be executed
[ok]: Pipelined commands after QUIT that exceed read buffer size
[5/46 done]: unit/quit (0 seconds)
Testing integration/replication
[ok]: Regression for a crash with blocking ops and pipelining
[ok]: BRPOPLPUSH with zero timeout should block indefinitely
[ok]: DEL against expired key
[ok]: EXISTS
[ok]: Zero length value in key. SET/GET/EXISTS
[6/46 done]: unit/protocol (1 seconds)
Testing integration/replication-2
[ok]: Commands pipelining
[ok]: Non existing command
[ok]: RENAME basic usage
[ok]: RENAME source key should no longer exist
[ok]: RENAME against already existing key
[ok]: RENAMENX basic usage
[ok]: RENAMENX against already existing key
[ok]: RENAMENX against already existing key (2)
[ok]: RENAME against non existing source key
[ok]: RENAME where source and dest key are the same (existing)
[ok]: RENAMENX where source and dest key are the same (existing)
[ok]: RENAME where source and dest key are the same (non existing)
[ok]: RENAME with volatile key, should move the TTL as well
[ok]: RENAME with volatile key, should not inherit TTL of target key
[ok]: DEL all keys again (DB 0)
[ok]: DEL all keys again (DB 1)
[ok]: MOVE basic usage
[ok]: MOVE against key existing in the target DB
[ok]: MOVE against non-integer DB (#1428)
[ok]: MOVE can move key expire metadata as well
[ok]: MOVE does not create an expire if it does not exist
[ok]: SET/GET keys in different DBs
[ok]: RANDOMKEY
[ok]: RANDOMKEY against empty DB
[ok]: RANDOMKEY regression 1
[ok]: KEYS * two times with long key, Github issue #1208
[ok]: FUZZ stresser with data model binary
[7/46 done]: unit/keyspace (1 seconds)
Testing integration/replication-3
[ok]: WATCH will not consider touched expired keys
[ok]: DISCARD should clear the WATCH dirty flag on the client
[ok]: DISCARD should UNWATCH all the keys
[ok]: FUZZ stresser with data model alpha
[ok]: MULTI / EXEC is propagated correctly (single write command)
[ok]: BRPOPLPUSH with a client BLPOPing the target list
[ok]: BRPOPLPUSH with wrong source type
[ok]: EXPIRE - After 2.1 seconds the key should no longer be here
[ok]: EXPIRE - write on expire should work
[ok]: EXPIREAT - Check for EXPIRE alike behavior
[ok]: SETEX - Set + Expire combo operation. Check for TTL
[ok]: SETEX - Check value
[ok]: SETEX - Overwrite old key
[ok]: MULTI / EXEC is propagated correctly (empty transaction)
[ok]: MULTI / EXEC is propagated correctly (read-only commands)
[ok]: Slave enters handshake
[ok]: MULTI / EXEC is propagated correctly (write command, no effect)
[ok]: First server should have role slave after SLAVEOF
[ok]: If min-slaves-to-write is honored, write is accepted
[ok]: No write if min-slaves-to-write is < attached slaves
[ok]: If min-slaves-to-write is honored, write is accepted (again)
[ok]: First server should have role slave after SLAVEOF
[8/46 done]: unit/multi (3 seconds)
Testing integration/replication-4
[ok]: Hash fuzzing #1 - 512 fields
[ok]: FUZZ stresser with data model compr
[ok]: Old Big Linked list: SORT BY key
[ok]: Old Big Linked list: SORT BY key with limit
[ok]: BRPOPLPUSH with wrong destination type
[ok]: BRPOPLPUSH maintains order of elements after failure
[ok]: BRPOPLPUSH with multiple blocked clients
[ok]: Linked BRPOPLPUSH
[ok]: Circular BRPOPLPUSH
[ok]: Self-referential BRPOPLPUSH
[ok]: BRPOPLPUSH inside a transaction
[ok]: PUSH resulting from BRPOPLPUSH affect WATCH
[ok]: BRPOPLPUSH does not affect WATCH while still blocked
[ok]: SETEX - Wait for the key to expire
[ok]: SETEX - Wrong time parameter
[ok]: PERSIST can undo an EXPIRE
[ok]: PERSIST returns 0 against non existing or non volatile keys
[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 128 element sorted set - ziplist
[ok]: Old Big Linked list: SORT BY hash field
[ok]: Intset: SORT BY key
[ok]: Intset: SORT BY key with limit
[ok]: Intset: SORT BY hash field
[ok]: BGSAVE
[ok]: SELECT an out of range DB
[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist
[ok]: First server should have role slave after SLAVEOF
[ok]: Hash table: SORT BY key
[ok]: Hash table: SORT BY key with limit
[ok]: Hash table: SORT BY hash field
[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist
[ok]: ZSETs skiplist implementation backlink consistency test - ziplist
[ok]: Hash fuzzing #2 - 512 fields
[ok]: EXPIRES after a reload (snapshot + append only file rewrite)
[ok]: BRPOPLPUSH timeout
[ok]: BLPOP when new key is moved into place
[ok]: BLPOP when result key is created by SORT..STORE
[ok]: BLPOP: with single empty list argument
[ok]: BLPOP: with negative timeout
[ok]: BLPOP: with non-integer timeout
[ok]: EXPIRE pricision is now the millisecond
[ok]: Very big payload random access
[ok]: BLPOP: with zero timeout should block indefinitely
[ok]: BLPOP: second argument is not a list
[ok]: ZSETs ZRANK augmented skip list stress testing - ziplist
[ok]: ZSCORE - skiplist
[ok]: ZSCORE after a DEBUG RELOAD - skiplist
[ok]: ZSET sorting stresser - skiplist
[ok]: SDIFF fuzzing
[ok]: SINTER against non-set should throw error
[ok]: SUNION against non-set should throw error
[ok]: SINTER should handle non existing key as empty
[ok]: SINTER with same integer elements but different encoding
[ok]: SINTERSTORE against non existing keys should delete dstkey
[ok]: SUNIONSTORE against non existing keys should delete dstkey
[ok]: SPOP basics - hashtable
[ok]: SPOP with <count>=1 - hashtable
[ok]: SRANDMEMBER - hashtable
[ok]: SPOP basics - intset
[ok]: SPOP with <count>=1 - intset
[ok]: SRANDMEMBER - intset
[ok]: SPOP with <count>
[ok]: SPOP with <count>
[ok]: SPOP using integers, testing Knuth's and Floyd's algorithm
[ok]: SPOP using integers with Knuth's algorithm
[ok]: SPOP new implementation: code path #1
[ok]: SPOP new implementation: code path #2
[ok]: SPOP new implementation: code path #3
[ok]: SRANDMEMBER with <count> against non existing key
[ok]: SRANDMEMBER with <count> - hashtable
[ok]: SRANDMEMBER with <count> - intset
[ok]: SMOVE basics - from regular set to intset
[ok]: SMOVE basics - from intset to regular set
[ok]: SMOVE non existing key
[ok]: SMOVE non existing src set
[ok]: SMOVE from regular set to non existing destination set
[ok]: SMOVE from intset to non existing destination set
[ok]: SMOVE wrong src key type
[ok]: SMOVE wrong dst key type
[ok]: SMOVE with identical source and destination
[ok]: PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires
[ok]: TTL returns tiem to live in seconds
[ok]: PTTL returns time to live in milliseconds
[ok]: TTL / PTTL return -1 if key has no expire
[ok]: TTL / PTTL return -2 if key does not exit
[ok]: Stress test the hash ziplist -> hashtable encoding conversion
[ok]: Test HINCRBYFLOAT for correct float representation (issue #2846)
[9/46 done]: unit/type/hash (7 seconds)
Testing integration/replication-psync
[ok]: BLPOP: timeout
[ok]: BLPOP: arguments are empty
[ok]: BRPOP: with single empty list argument
[ok]: BRPOP: with negative timeout
[ok]: BRPOP: with non-integer timeout
[ok]: EXPIRES after AOF reload (without rewrite)
[ok]: Redis should actively expire keys incrementally
[ok]: intsets implementation stress testing
[ok]: No write if min-slaves-max-lag is > of the slave lag
[ok]: min-slaves-to-write is ignored by slaves
[10/46 done]: unit/type/set (9 seconds)
Testing integration/aof
[ok]: BRPOP: with zero timeout should block indefinitely
[ok]: BRPOP: second argument is not a list
[ok]: Unfinished MULTI: Server should start if load-truncated is yes
[ok]: Slave should be able to synchronize with the master
[ok]: Detect write load to master
[ok]: SET 10000 numeric keys and access all them in reverse order
[ok]: DBSIZE should be 10000 now
[ok]: SETNX target key missing
[ok]: SETNX target key exists
[ok]: SETNX against not-expired volatile key
[ok]: Redis should lazy expire keys
[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, reconnect: 0)
[ok]: Big Hash table: SORT BY key
[ok]: Big Hash table: SORT BY key with limit
[ok]: Short read: Server should start if load-truncated is yes
[ok]: Truncated AOF loaded: we expect foo to be equal to 5
[ok]: Append a new command after loading an incomplete AOF
[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 100 element sorted set - skiplist
[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist
[ok]: Short read + command: Server should start
[ok]: Truncated AOF loaded: we expect foo to be equal to 6 now
[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist
[ok]: ZSETs skiplist implementation backlink consistency test - skiplist
[ok]: EXPIRE should not resurrect keys (issue #1026)
[ok]: 5 keys in, 5 keys out
[ok]: EXPIRE with empty string as TTL should report an error
[ok]: Big Hash table: SORT BY hash field
[ok]: SORT GET #
[ok]: SORT GET <const>
[ok]: SORT GET (key and hash) with sanity check
[ok]: SORT BY key STORE
[ok]: SORT BY hash field STORE
[ok]: SORT extracts STORE correctly
[ok]: SORT extracts multiple STORE correctly
[ok]: SORT DESC
[ok]: SORT ALPHA against integer encoded strings
[ok]: SORT sorted set
[ok]: SORT sorted set BY nosort should retain ordering
[ok]: SORT sorted set BY nosort + LIMIT
[ok]: SORT sorted set BY nosort works as expected from scripts
[ok]: SORT sorted set: +inf and -inf handling
[ok]: SORT regression for issue #19, sorting floats
[ok]: SORT with STORE returns zero if result is empty (github issue 224)
[ok]: SORT with STORE does not create empty lists (github issue 224)
[ok]: SORT with STORE removes key if result is empty (github issue 227)
[ok]: SORT with BY <constant> and STORE should still order output
[ok]: SORT will complain with numerical sorting and bad doubles (1)
[ok]: SORT will complain with numerical sorting and bad doubles (2)
[ok]: SORT BY sub-sorts lexicographically if score is the same
[ok]: SORT GET with pattern ending with just -> does not get hash field
[ok]: SORT by nosort retains native order for lists
[ok]: SORT by nosort plus store retains native order for lists
[ok]: SORT by nosort with limit returns based on original list order
[ok]: Bad format: Server should have logged an error
[ok]: SORT speed, 100 element list BY key, 100 times
[ok]: SORT speed, 100 element list BY hash field, 100 times
[ok]: SORT speed, 100 element list directly, 100 times
[ok]: SORT speed, 100 element list BY <const>, 100 times
[ok]: Unfinished MULTI: Server should have logged an error
[11/46 done]: unit/sort (11 seconds)
Testing integration/rdb
[ok]: LTRIM stress testing - linkedlist
[ok]: BRPOP: timeout
[ok]: BRPOP: arguments are empty
[ok]: BLPOP inside a transaction
[ok]: LPUSHX, RPUSHX - generic
[ok]: LPUSHX, RPUSHX - linkedlist
[ok]: LINSERT - linkedlist
[ok]: LPUSHX, RPUSHX - ziplist
[ok]: LINSERT - ziplist
[ok]: LINSERT raise error on bad syntax
[ok]: Slave should be able to synchronize with the master
[ok]: Detect write load to master
[ok]: Short read: Server should have logged an error
[ok]: LINDEX consistency test - quicklist
[ok]: ZSETs ZRANK augmented skip list stress testing - skiplist
[ok]: Test replication with parallel clients writing in differnet DBs
[ok]: LINDEX random access - quicklist
[ok]: Short read: Utility should confirm the AOF is not valid
[ok]: RDB encoding loading test
[ok]: Short read: Utility should be able to fix the AOF
[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist
[12/46 done]: unit/type/zset (11 seconds)
Testing integration/convert-zipmap-hash-on-load
[ok]: LINDEX consistency test - quicklist
[ok]: PIPELINING stresser (also a regression for the old epoll bug)
[ok]: APPEND basics
[ok]: APPEND basics, integer encoded values
[ok]: LINDEX random access - quicklist
[ok]: Fixed AOF: Server should have been started
[ok]: Fixed AOF: Keyspace should contain values that were parseable
[ok]: Server started empty with non-existing RDB file
[ok]: RDB load zipmap hash: converts to ziplist
[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist
[ok]: LLEN against non-list value error
[ok]: LLEN against non existing key
[ok]: LINDEX against non-list value error
[ok]: LINDEX against non existing key
[ok]: LPUSH against non-list value error
[ok]: RPUSH against non-list value error
[ok]: RPOPLPUSH base case - linkedlist
[ok]: RPOPLPUSH with the same list as src and dst - linkedlist
[ok]: RPOPLPUSH with linkedlist source and existing target linkedlist
[ok]: RPOPLPUSH with linkedlist source and existing target ziplist
[ok]: RPOPLPUSH base case - ziplist
[ok]: RPOPLPUSH with the same list as src and dst - ziplist
[ok]: RPOPLPUSH with ziplist source and existing target linkedlist
[ok]: RPOPLPUSH with ziplist source and existing target ziplist
[ok]: RPOPLPUSH against non existing key
[ok]: RPOPLPUSH against non list src key
[ok]: RPOPLPUSH against non list dst key
[ok]: RPOPLPUSH against non existing src key
[ok]: Basic LPOP/RPOP - linkedlist
[ok]: Basic LPOP/RPOP - ziplist
[ok]: LPOP/RPOP against non list value
[ok]: Mass RPOP/LPOP - quicklist
[ok]: APPEND fuzzing
[ok]: Mass RPOP/LPOP - quicklist
[ok]: LRANGE basics - linkedlist
[ok]: LRANGE inverted indexes - linkedlist
[ok]: LRANGE out of range indexes including the full list - linkedlist
[ok]: LRANGE out of range negative end index - linkedlist
[ok]: LRANGE basics - ziplist
[ok]: LRANGE inverted indexes - ziplist
[ok]: LRANGE out of range indexes including the full list - ziplist
[ok]: LRANGE out of range negative end index - ziplist
[ok]: LRANGE against non existing key
[ok]: LTRIM basics - linkedlist
[ok]: LTRIM out of range negative end index - linkedlist
[ok]: LTRIM basics - ziplist
[ok]: LTRIM out of range negative end index - ziplist
[ok]: LSET - linkedlist
[ok]: LSET out of range index - linkedlist
[ok]: LSET - ziplist
[ok]: LSET out of range index - ziplist
[ok]: LSET against non existing key
[ok]: LSET against non list value
[ok]: LREM remove all the occurrences - linkedlist
[ok]: LREM remove the first occurrence - linkedlist
[ok]: LREM remove non existing element - linkedlist
[ok]: LREM starting from tail with negative count - linkedlist
[ok]: LREM starting from tail with negative count (2) - linkedlist
[ok]: LREM deleting objects that may be int encoded - linkedlist
[ok]: LREM remove all the occurrences - ziplist
[ok]: LREM remove the first occurrence - ziplist
[ok]: LREM remove non existing element - ziplist
[ok]: LREM starting from tail with negative count - ziplist
[ok]: LREM starting from tail with negative count (2) - ziplist
[ok]: LREM deleting objects that may be int encoded - ziplist
[ok]: AOF+SPOP: Server should have been started
[ok]: AOF+SPOP: Set should have 1 member
[ok]: SETNX against expired volatile key
[ok]: MGET
[ok]: MGET against non existing key
[ok]: MGET against non-string key
[ok]: GETSET (set new value)
[ok]: GETSET (replace old value)
[ok]: MSET base case
[ok]: MSET wrong number of args
[ok]: MSETNX with already existent key
[ok]: MSETNX with not existing keys
[ok]: STRLEN against non-existing key
[ok]: STRLEN against integer-encoded value
[ok]: STRLEN against plain string
[ok]: SETBIT against non-existing key
[ok]: SETBIT against string-encoded key
[ok]: SETBIT against integer-encoded key
[ok]: SETBIT against key with wrong type
[ok]: SETBIT with out of range bit offset
[ok]: SETBIT with non-bit argument
[ok]: Server started empty with empty RDB file
[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-entries is exceeded
[ok]: FLUSHDB
[ok]: Perform a final SAVE to leave a clean DB on disk
[13/46 done]: unit/other (12 seconds)
Testing integration/logging
[ok]: Server should not start if RDB is corrupted
[14/46 done]: integration/rdb (1 seconds)
Testing integration/psync2
[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-value is exceeded
[ok]: AOF+SPOP: Server should have been started
[ok]: AOF+SPOP: Set should have 1 member
[15/46 done]: integration/convert-zipmap-hash-on-load (1 seconds)
Testing integration/psync2-reg
[ok]: SETBIT fuzzing
[ok]: GETBIT against non-existing key
[ok]: GETBIT against string-encoded key
[ok]: GETBIT against integer-encoded key
[ok]: SETRANGE against non-existing key
[ok]: SETRANGE against string-encoded key
[ok]: SETRANGE against integer-encoded key
[ok]: SETRANGE against key with wrong type
[ok]: SETRANGE with out of range offset
[ok]: GETRANGE against non-existing key
[ok]: GETRANGE against string value
[ok]: GETRANGE against integer-encoded value
[ok]: Slave is able to detect timeout during handshake
[ok]: Server is able to generate a stack trace on selected systems
[16/46 done]: integration/logging (1 seconds)
Testing unit/pubsub
[ok]: Regression for bug 593 - chaining BRPOPLPUSH with other blocking cmds
[ok]: AOF+EXPIRE: Server should have been started
[ok]: AOF+EXPIRE: List should be empty
[ok]: Pub/Sub PING
[ok]: PUBLISH/SUBSCRIBE basics
[ok]: PUBLISH/SUBSCRIBE with two clients
[ok]: PUBLISH/SUBSCRIBE after UNSUBSCRIBE without arguments
[ok]: SUBSCRIBE to one channel more than once
[ok]: UNSUBSCRIBE from non-subscribed channels
[ok]: PUBLISH/PSUBSCRIBE basics
[ok]: PUBLISH/PSUBSCRIBE with two clients
[ok]: PUBLISH/PSUBSCRIBE after PUNSUBSCRIBE without arguments
[ok]: PUNSUBSCRIBE from non-subscribed channels
[ok]: NUMSUB returns numbers, not strings (#1561)
[ok]: Mix SUBSCRIBE and PSUBSCRIBE
[ok]: PUNSUBSCRIBE and UNSUBSCRIBE should always reply
[ok]: Keyspace notifications: we receive keyspace notifications
[ok]: Keyspace notifications: we receive keyevent notifications
[ok]: Keyspace notifications: we can receive both kind of events
[ok]: Keyspace notifications: we are able to mask events
[ok]: Keyspace notifications: general events test
[ok]: Keyspace notifications: list events test
[ok]: Keyspace notifications: set events test
[ok]: Keyspace notifications: zset events test
[ok]: Keyspace notifications: hash events test
[17/46 done]: unit/type/list (13 seconds)
Testing unit/slowlog
[ok]: First server should have role slave after SLAVEOF
[ok]: With min-slaves-to-write (1,3): master should be writable
[ok]: With min-slaves-to-write (2,3): master should not be writable
[ok]: Keyspace notifications: expired events (triggered expire)
[ok]: Redis should not try to convert DEL into EXPIREAT for EXPIRE -1
[ok]: SLOWLOG - check that it starts with an empty log
[ok]: Keyspace notifications: expired events (background expire)
[ok]: Keyspace notifications: evicted events
[ok]: Keyspace notifications: test CONFIG GET/SET of event flags
[ok]: PSYNC2: --- CYCLE 1 ---
[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master
[ok]: PSYNC2: Set #2 to replicate from #1
[ok]: PSYNC2: Set #0 to replicate from #1
[ok]: PSYNC2: Set #4 to replicate from #0
[ok]: PSYNC2: Set #3 to replicate from #1
[ok]: SLOWLOG - only logs commands taking more time than specified
[ok]: SLOWLOG - max entries is correctly handled
[ok]: SLOWLOG - GET optional argument to limit output len works
[ok]: SLOWLOG - RESET subcommand works
[18/46 done]: unit/pubsub (0 seconds)
Testing unit/scripting
[19/46 done]: integration/aof (4 seconds)
Testing unit/maxmemory
[ok]: SLOWLOG - logged entry sanity check
[ok]: SLOWLOG - commands with too many arguments are trimmed
[ok]: SLOWLOG - too long arguments are trimmed
[ok]: GETRANGE fuzzing
[ok]: Extended SET can detect syntax errors
[ok]: Extended SET NX option
[ok]: Extended SET XX option
[ok]: Extended SET EX option
[ok]: Extended SET PX option
[ok]: Extended SET using multiple options at once
[ok]: GETRANGE with huge ranges, Github issue #1844
[ok]: Without maxmemory small integers are shared
[ok]: With maxmemory and non-LRU policy integers are still shared
[ok]: With maxmemory and LRU policy integers are not shared
[ok]: EVAL - Does Lua interpreter replies to our requests?
[ok]: EVAL - Lua integer -> Redis protocol type conversion
[ok]: EVAL - Lua string -> Redis protocol type conversion
[ok]: EVAL - Lua true boolean -> Redis protocol type conversion
[ok]: EVAL - Lua false boolean -> Redis protocol type conversion
[ok]: EVAL - Lua status code reply -> Redis protocol type conversion
[ok]: EVAL - Lua error reply -> Redis protocol type conversion
[ok]: EVAL - Lua table -> Redis protocol type conversion
[ok]: EVAL - Are the KEYS and ARGV arrays populated correctly?
[ok]: EVAL - is Lua able to call Redis API?
[ok]: EVALSHA - Can we call a SHA1 if already defined?
[ok]: EVALSHA - Can we call a SHA1 in uppercase?
[ok]: EVALSHA - Do we get an error on invalid SHA1?
[ok]: EVALSHA - Do we get an error on non defined SHA1?
[ok]: EVAL - Redis integer -> Lua type conversion
[ok]: EVAL - Redis bulk -> Lua type conversion
[ok]: EVAL - Redis multi bulk -> Lua type conversion
[ok]: EVAL - Redis status reply -> Lua type conversion
[ok]: EVAL - Redis error reply -> Lua type conversion
[ok]: EVAL - Redis nil bulk reply -> Lua type conversion
[ok]: EVAL - Is the Lua client using the currently selected DB?
[ok]: EVAL - SELECT inside Lua should not affect the caller
[ok]: EVAL - Scripts can't run certain commands
[ok]: EVAL - Scripts can't run certain commands
[ok]: EVAL - No arguments to redis.call/pcall is considered an error
[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)
[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)
[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)
[ok]: EVAL - JSON numeric decoding
[ok]: EVAL - JSON string decoding
[ok]: EVAL - cmsgpack can pack double?
[ok]: EVAL - cmsgpack can pack negative int64?
[ok]: EVAL - cmsgpack can pack and unpack circular references?
[ok]: EVAL - Numerical sanity check from bitop
[ok]: EVAL - Verify minimal bitop functionality
[ok]: EVAL - Able to parse trailing comments
[ok]: SCRIPTING FLUSH - is able to clear the scripts cache?
[ok]: SCRIPT EXISTS - can detect already defined scripts?
[ok]: SCRIPT LOAD - is able to register scripts in the scripting cache
[ok]: In the context of Lua the output of random commands gets ordered
[ok]: SORT is normally not alpha re-ordered for the scripting engine
[ok]: SORT BY <constant> output gets ordered for scripting
[ok]: SORT BY <constant> with GET gets ordered for scripting
[ok]: redis.sha1hex() implementation
[ok]: Globals protection reading an undeclared global variable
[ok]: Globals protection setting an undeclared global*
[ok]: Test an example script DECR_IF_GT
[ok]: Scripting engine resets PRNG at every script execution
[ok]: Scripting engine PRNG can be seeded correctly
[ok]: SLOWLOG - EXEC is not logged, just executed commands
[20/46 done]: unit/type/string (14 seconds)
Testing unit/introspection
[ok]: EVAL does not leak in the Lua stack
[ok]: CLIENT LIST
[ok]: MONITOR can log executed commands
[ok]: SLOWLOG - can clean older entires
[ok]: MONITOR can log commands issued by the scripting engine
[ok]: CLIENT GETNAME should return NIL if name is not assigned
[ok]: CLIENT LIST shows empty fields for unassigned names
[ok]: CLIENT SETNAME does not accept spaces
[ok]: CLIENT SETNAME can assign a name to this connection
[ok]: CLIENT SETNAME can change the name of an existing connection
[ok]: After CLIENT SETNAME, connection can still be closed
[21/46 done]: unit/introspection (0 seconds)
Testing unit/introspection-2
[ok]: EVAL processes writes from AOF in read-only slaves
[ok]: We can call scripts rewriting client->argv from Lua
[ok]: Call Redis command with many args from Lua (issue #1764)
[ok]: Number conversion precision test (issue #1118)
[ok]: String containing number precision test (regression of issue #1118)
[ok]: Verify negative arg count is error instead of crash (issue #1842)
[ok]: Correct handling of reused argv (issue #1939)
[ok]: Functions in the Redis namespace are able to report errors
[ok]: maxmemory - is the memory limit honoured? (policy allkeys-random)
[ok]: Set instance A as slave of B
[ok]: BRPOPLPUSH replication, when blocking against empty list
[ok]: PSYNC2 #3899 regression: setup
[ok]: SET - use EX/PX option, TTL should not be reseted after loadaof
[22/46 done]: unit/slowlog (1 seconds)
Testing unit/limits

Logged warnings (pid 1112):
(none)

[23/46 done]: unit/expire (14 seconds)
Testing unit/obuf-limits
[ok]: MASTER and SLAVE consistency with expire

Logged warnings (pid 1068):
(none)

[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lru)

Logged warnings (pid 1021):
(none)

[exception]: Executing test client: couldn't execute "src/redis-benchmark": no such file or directory.
couldn't execute "src/redis-benchmark": no such file or directory
    while executing
"exec src/redis-benchmark -p $R_port(0) -n 10000000 -r 1000 incr __rand_int__ > /dev/null &"
    ("uplevel" body line 31)
    invoked from within
"uplevel 1 $code "
    (procedure "start_server" line 3)
    invoked from within
"start_server {} {
    # Config
    set debug_msg 0                 ; # Enable additional debug messages

    set no_exit 0                   ; # Do no..."
    ("uplevel" body line 2)
    invoked from within
"uplevel 1 $code "
    (procedure "start_server" line 3)
    invoked from within
"start_server {} {
start_server {} {
    # Config
    set debug_msg 0                 ; # Enable additional debug messages

    set no_exit 0          ..."
    ("uplevel" body line 2)
    invoked from within
"uplevel 1 $code "
    (procedure "start_server" line 3)
    invoked from within
"start_server {tags {"psync2"}} {
start_server {} {
start_server {} {
    # Config
    set debug_msg 0                 ; # Enable additional debug mess..."
    (file "tests/integration/psync2-reg.tcl" line 7)
    invoked from within
"source $path"
    (procedure "execute_tests" line 4)
    invoked from within
"execute_tests $data"
    (procedure "test_client_main" line 10)
    invoked from within
"test_client_main $::test_server_port "
Killing still running Redis server 259
Killing still running Redis server 261
Killing still running Redis server 271
Killing still running Redis server 481
Killing still running Redis server 536
Killing still running Redis server 548
Killing still running Redis server 560
Killing still running Redis server 569
Killing still running Redis server 712
Killing still running Redis server 731
I/O error reading reply
    while executing
"{*}$r sunionstore $k2 $k $otherset"
    ("uplevel" body line 2)
    invoked from within
"uplevel 1 [lindex $args $path]"
    (procedure "randpath" line 3)
    invoked from within
"randpath {
                                    {*}$r sunionstore $k2 $k $otherset
                                } {
                                ..."
    ("uplevel" body line 4)
    invoked from within
"uplevel 1 [lindex $args $path]"
    (procedure "randpath" line 3)
    invoked from within
"randpath {{*}$r sadd $k $v}  {{*}$r srem $k $v}  {
                            set otherset [findKeyWithType {*}$r set]
                            if..."
    (procedure "createComplexDataset" line 54)
    invoked from within
"createComplexDataset $r $ops"
    (procedure "bg_complex_data" line 4)
    invoked from within
"bg_complex_data [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]"
    (file "tests/helpers/bg_complex_data.tcl" line 10)
I/O error reading reply
    while executing
"{*}$r set $k $v"
    ("uplevel" body line 2)
    invoked from within
"uplevel 1 [lindex $args $path]"
    (procedure "randpath" line 3)
    invoked from within
"randpath {
                {*}$r set $k $v
            } {
                {*}$r lpush $k $v
            } {
                {*}$r sadd $k $v
        ..."
    (procedure "createComplexDataset" line 30)
    invoked from within
"createComplexDataset $r $ops"
    (procedure "bg_complex_data" line 4)
    invoked from within
"bg_complex_data [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]"
    (file "tests/helpers/bg_complex_data.tcl" line 10)
I/O error reading reply
    while executing
"{*}$r type $k"
    (procedure "createComplexDataset" line 27)
    invoked from within
"createComplexDataset $r $ops"
    (procedure "bg_complex_data" line 4)
    invoked from within
"bg_complex_data [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]"
    (file "tests/helpers/bg_complex_data.tcl" line 10)
Killing still running Redis server 751
Killing still running Redis server 761
Killing still running Redis server 776
Killing still running Redis server 864
Killing still running Redis server 906
Killing still running Redis server 940
Killing still running Redis server 984
Killing still running Redis server 1011
Killing still running Redis server 1038
Killing still running Redis server 1088
Killing still running Redis server 1106
Killing still running Redis server 1139
Killing still running Redis server 1152
Killing still running Redis server 1193
Killing still running Redis server 1244
Killing still running Redis server 1261
Killing still running Redis server 1278
Killing still running Redis server 1296
make[1]: *** [Makefile:242: test] Error 1
make[1]: Leaving directory '/benchmark-scripts/redis-src/src'
make: *** [Makefile:6: test] Error 2
